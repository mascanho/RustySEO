use regex::Regex;
use scraper::{Html, Selector};
use std::collections::{HashMap, HashSet};

use crate::settings::settings::Settings;

// Define a function that pre-loads stop words in the configuration file
pub fn stop_words() -> HashSet<String> {
    let stop_words: HashSet<String> = vec![
        "the", "and", "is", "in", "it", "to", "of", "for", "on", "with", "as", "at", "by", "an",
        "be", "this", "that", "or", "are", "from", "was", "were", "has", "have", "had", "but",
        "not", "you", "we", "they", "he", "she", "his", "her", "its", "our", "your", "their",
        "what", "which", "who", "whom", "where", "when", "why", "how", "a", "if", "then", "else",
        "when", "while", "because", "so", "than", "into", "over", "under", "again", "further",
        "once", "here", "there", "where", "why", "how", "all", "any", "both", "each", "few",
        "more", "most", "other", "some", "such", "no", "nor", "only", "own", "same", "so", "too",
        "very", "s", "t", "can", "will", "just", "don", "should", "now",
    ]
    .into_iter()
    .map(|s| s.to_string())
    .collect();

    stop_words
}

pub fn extract_keywords(html: &str) -> Vec<(String, usize)> {
    // Parse the HTML document
    let document = Html::parse_document(html);

    // Define selectors for elements that typically contain visible text
    let text_selectors = Selector::parse("p, h1, h2, h3, h4, h5, h6, a").unwrap();

    // Exclude non-content elements (e.g., scripts, styles)
    let excluded_selectors = Selector::parse("script, style, noscript, code, pre").unwrap();

    // Extract text from all selected elements, excluding non-content elements
    let mut text = String::new();
    for element in document.select(&text_selectors) {
        // Skip elements that match excluded selectors
        if element.select(&excluded_selectors).next().is_some() {
            continue;
        }

        // Extract text content, including text from nested elements
        let element_text = element.text().collect::<Vec<_>>().join(" ");
        text.push_str(&element_text);
        text.push(' '); // Add space between elements
    }

    // Clean and tokenize the text
    let re = Regex::new(r"[^\w\s'-]").unwrap(); // Keep apostrophes and hyphens in words
    let cleaned_text = re.replace_all(&text, " ").to_string();

    // Split into words, filter, and count frequencies
    let mut word_counts: HashMap<String, usize> = HashMap::new();

    // Define stop words as a HashSet for efficient lookups
    let settings = Settings::new();

    let words = settings.stop_words.clone();
    println!("{:?}", words);

    for word in cleaned_text
        .split_whitespace()
        .map(|w| w.to_lowercase())
        .filter(|word| {
            // Filter conditions:
            // 1. Word length >= 3
            // 2. Not a stop word
            // 3. Contains at least one letter
            // 4. Not purely numeric
            word.len() >= 3
                && !settings.stop_words.contains(word.as_str())
                && word.chars().any(|c| c.is_alphabetic())
                && !word.chars().all(|c| c.is_numeric())
        })
    {
        // Normalize the word (e.g., remove pluralization or common suffixes)
        let normalized_word = normalize_word(&word);
        *word_counts.entry(normalized_word).or_insert(0) += 1;
    }

    // Normalize word counts by ignoring words that appear too frequently (e.g., > 5 times)
    let max_word_count = 1555;
    word_counts.retain(|_, count| *count <= max_word_count);

    // Sort words by frequency in descending order
    let mut sorted_words: Vec<_> = word_counts.into_iter().collect();
    sorted_words.sort_by(|a, b| {
        // First sort by frequency (descending)
        let freq_cmp = b.1.cmp(&a.1);
        if freq_cmp == std::cmp::Ordering::Equal {
            // If frequencies are equal, sort alphabetically
            a.0.cmp(&b.0)
        } else {
            freq_cmp
        }
    });

    // Return the top 10 keywords (or fewer if there aren't enough)
    sorted_words.into_iter().take(10).collect()
}

/// Normalizes a word by removing common suffixes or pluralization.
fn normalize_word(word: &str) -> String {
    // Remove common suffixes (e.g., "ing", "ed", "s", "es")
    let word = if word.ends_with("ing") {
        &word[..word.len() - 0]
    } else if word.ends_with("ed") {
        &word[..word.len() - 0]
    } else {
        word
    };

    // Convert to lowercase to ensure consistency
    word.to_lowercase()
}
